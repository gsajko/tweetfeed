{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from twitter_to_sqlite import utils\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = json.load(open(\"../auth/auth.json\"))\n",
    "owner_id = \"143058191\"\n",
    "session = utils.session_for_auth(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_collection(collection_id, session=session):\n",
    "    url = f\"https://api.twitter.com/1.1/collections/entries.json?id={collection_id}&count=200\"\n",
    "    response = session.get(url)\n",
    "    collection_tweets = response.json()\n",
    "    try:\n",
    "        collection_tweets = list(collection_tweets[\"objects\"][\"tweets\"])\n",
    "        if len(collection_tweets) < 100:\n",
    "            print(f\"{collection_id} contains {len(collection_tweets)} tweets\")\n",
    "        else:\n",
    "            print(f\"{collection_id} contains more then 100 tweets\")\n",
    "        return len(collection_tweets)\n",
    "    except:\n",
    "        print(f\"{collection_id} contains 0 tweets\")\n",
    "        return 0\n",
    "\n",
    "\n",
    "def get_list_id(owner_id, list_name, session=session):\n",
    "    url = f\"https://api.twitter.com/1.1/lists/list.json?user_id={owner_id}\"\n",
    "    response = session.get(url)\n",
    "    for l in response.json():\n",
    "        if l[\"name\"] == list_name:\n",
    "            return l[\"id\"]\n",
    "\n",
    "\n",
    "def get_collection_id(owner_id, collection_name, session=session):\n",
    "    url = f\"https://api.twitter.com/1.1/collections/list.json?user_id={owner_id}\"\n",
    "    response = session.get(url)\n",
    "    collections = response.json()[\"objects\"][\"timelines\"]\n",
    "    for k in collections.keys():\n",
    "        if collections[k][\"name\"] == collection_name:\n",
    "            return k\n",
    "\n",
    "\n",
    "def err_handling(response, sleep=60):\n",
    "    while response.reason != \"OK\":\n",
    "        print(response.reason)\n",
    "        if response.reason == \"Too Many Requests\":\n",
    "            print(f\"Rate limit error - waiting for {sleep} seconds\")\n",
    "            time.sleep(sleep)\n",
    "        else:\n",
    "            if \"errors\" in response.json():\n",
    "                print(response.json()[\"errors\"][0][\"message\"])\n",
    "            elif \"error\" in response.json():\n",
    "                print(response.json()[\"error\"])\n",
    "            else:\n",
    "                print(response.json())\n",
    "            raise Exception(f\"Status code: {response.status_code}\")\n",
    "\n",
    "\n",
    "def rem_from_collection(collection_id, session=session):\n",
    "    url = f\"https://api.twitter.com/1.1/collections/entries.json?id={collection_id}&count=200\"\n",
    "    response = session.get(url)\n",
    "    collection_tweets = response.json()\n",
    "    try:\n",
    "        collection_tweets = list(collection_tweets[\"objects\"][\"tweets\"])\n",
    "    except:\n",
    "        print(f\"{collection_id} contains 0 tweets\")\n",
    "    for t in collection_tweets:\n",
    "        url = f\"https://api.twitter.com/1.1/collections/entries/remove.json?id={collection_id}&tweet_id={t}\"\n",
    "        response = session.post(url)\n",
    "        err_handling(response)\n",
    "    count_collection(collection_id)\n",
    "\n",
    "\n",
    "def processing_list(collection_id, tweet_list):\n",
    "    collection_id = collection_id\n",
    "    procc_list = []\n",
    "    for counter, tweet_id in enumerate(tweet_list):\n",
    "        if (counter + 1) % 20 == 0:\n",
    "            print(f\"{(counter+1)} / {len(tweet_list)}\")\n",
    "        url = f\"https://api.twitter.com/1.1/collections/entries/add.json?tweet_id={tweet_id}&id={collection_id}\"\n",
    "        response = session.post(url)\n",
    "        err_handling(response)\n",
    "        if response.reason == \"OK\":\n",
    "            errors = response.json()[\"response\"][\"errors\"]\n",
    "            if len(errors) > 0:\n",
    "                procc_list.append(\n",
    "                    {\"tweet_id\": tweet_id, \"err_reason\": errors[0][\"reason\"]}\n",
    "                )\n",
    "            else:\n",
    "                procc_list.append({\"tweet_id\": tweet_id, \"err_reason\": \"no_errors\"})\n",
    "    df = pd.DataFrame(procc_list)\n",
    "    print(df[\"err_reason\"].value_counts())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# show collections\n",
    "url = f\"https://api.twitter.com/1.1/collections/list.json?user_id={owner_id}\"\n",
    "response = session.get(url)\n",
    "def create_collection(owner_id, session=session):\n",
    "    try:\n",
    "        collections = response.json()[\"objects\"][\"timelines\"]\n",
    "        for k in collections.keys():\n",
    "            print(k, collections[k][\"name\"])\n",
    "        collections_list = [collections[k][\"name\"] for k in collections.keys()]\n",
    "    except:\n",
    "        collections = []\n",
    "        print(\"no collections\")\n",
    "        collections_list = []\n",
    "\n",
    "    collections_for_classification = [\"custom_newsfeed\", \"not_relevant\"]\n",
    "    print(\"\")\n",
    "    for c in collections_for_classification:\n",
    "        if c not in collections_list:\n",
    "            print(f\"[{c}] not in collections, creating new collection\")\n",
    "            url = f\"https://api.twitter.com/1.1/collections/create.json?name={c}\"\n",
    "            session.post(url)\n",
    "        else:\n",
    "            print(f\"collection [{c}] already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom-1351555076024893440 contains more then 100 tweets\n",
      "custom-1351093543385899011 contains more then 100 tweets\n"
     ]
    }
   ],
   "source": [
    "url = f\"https://api.twitter.com/1.1/collections/list.json?user_id={owner_id}\"\n",
    "response = session.get(url)\n",
    "collection_tweets = response.json()\n",
    "\n",
    "for collection_id in collections:\n",
    "    count_collection(collection_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add tweets to collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## filter out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get members of list called `muted`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df = pd.read_csv(\"batch_to_add.csv\")\n",
    "# this df is already filtered - removed \"new\" tweets, remove news, removed \"seen\" tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1351254441798807555"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "muted_list = get_list_id(owner_id, \"muted\")\n",
    "muted_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = f\"https://api.twitter.com/1.1/lists/members.json?list_id={muted_list}&owner_id={owner_id}\"\n",
    "response = session.get(url)\n",
    "muted_accounts = [i[\"id\"] for i in response.json()[\"users\"]]\n",
    "len(muted_accounts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df[tweets_df[\"user\"].isin(muted_accounts)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(933, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df = tweets_df[~tweets_df[\"user\"].isin(muted_accounts)]\n",
    "tweets_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add tweets from csv to collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## remove tweets from custom newsweed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'custom-1351555076024893440'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_newsfeed = get_collection_id(owner_id, \"custom_newsfeed\")\n",
    "custom_newsfeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'custom_newsfeed',\n",
       " 'user_id': '143058191',\n",
       " 'collection_url': 'https://twitter.com/saiko_grzegorz/timelines/1351555076024893440',\n",
       " 'custom_timeline_url': 'https://twitter.com/saiko_grzegorz/timelines/1351555076024893440',\n",
       " 'description': '',\n",
       " 'url': 'https://twitter.com/saiko_grzegorz/timelines/1351555076024893440',\n",
       " 'visibility': 'public',\n",
       " 'timeline_order': 'curation_reverse_chron',\n",
       " 'collection_type': 'user',\n",
       " 'custom_timeline_type': 'user'}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections[custom_newsfeed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom-1351555076024893440 contains more then 100 tweets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "139"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_collection(custom_newsfeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'custom-1351555076024893440'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_newsfeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom-1351555076024893440 contains 0 tweets\n"
     ]
    }
   ],
   "source": [
    "while count_collection(custom_newsfeed) > 0:\n",
    "    rem_from_collection(custom_newsfeed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add n tweets from batch to collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_list = tweets_df[\"id\"].tolist()[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_list = [\"1335672354849091589\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not_found    1\n",
      "Name: err_reason, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = processing_list(custom_newsfeed, tweet_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweets_df[\"id\"][:200].to_csv('seen.csv', mode='a', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweet_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seen_tweets_old = pd.read_csv(\"seen.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "seen_tweets_old.to_csv(\"seen_old.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"seen.csv\", mode=\"a\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>err_reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1337875267096875015</td>\n",
       "      <td>no_errors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1335698027537969155</td>\n",
       "      <td>no_errors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1345699105385959435</td>\n",
       "      <td>not_found</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1336874318882467842</td>\n",
       "      <td>no_errors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1337717825629253633</td>\n",
       "      <td>not_found</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id err_reason\n",
       "0  1337875267096875015  no_errors\n",
       "1  1335698027537969155  no_errors\n",
       "2  1345699105385959435  not_found\n",
       "3  1336874318882467842  no_errors\n",
       "4  1337717825629253633  not_found"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seen_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no_errors          1857\n",
       "not_found           608\n",
       "protected_tweet      35\n",
       "Name: err_reason, dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seen_tweets[\"err_reason\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save not_relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_collection_list(collection_id, session=session):\n",
    "    url = f\"https://api.twitter.com/1.1/collections/entries.json?id={collection_id}&count=200\"\n",
    "    response = session.get(url)\n",
    "    collection_tweets = response.json()\n",
    "    try:\n",
    "        collection_tweets = list(collection_tweets[\"objects\"][\"tweets\"])\n",
    "        return collection_tweets\n",
    "    except:\n",
    "        print(f\"{collection_id} contains 0 tweets\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_relevant_list = get_collection_list(get_collection_id(owner_id, \"not_relevant\"))\n",
    "with open(f\"{datetime.now():%Y_%m_%d_%H%M}_not_relevant_list.txt\", \"w\") as f:\n",
    "    f.write(json.dumps(not_relevant_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2021_01_22_1547_not_relevant_list.txt\r\n",
      "'2nd batch.csv'\r\n",
      " 3nd_batch.csv\r\n",
      " 4nd_batch.csv\r\n",
      " 5nd_batch.csv\r\n",
      "'add sleep to function.ipynb'\r\n",
      "'auth and get friends.ipynb'\r\n",
      " auth.json\r\n",
      " batch_to_add.csv\r\n",
      " cli_click.py\r\n",
      " collections.ipynb\r\n",
      " create_news_domains_list.ipynb\r\n",
      " db.ipynb\r\n",
      " db.py\r\n",
      " dbsw.py\r\n",
      " df.csv\r\n",
      "'embed tweet.ipynb'\r\n",
      "'extract from url.ipynb'\r\n",
      " first_batch.csv\r\n",
      "'grab 1000 tweets.ipynb'\r\n",
      "'hud queries.ipynb'\r\n",
      " identify_news.ipynb\r\n",
      " __init__.py\r\n",
      " news_domains.txt\r\n",
      " news_sites.csv\r\n",
      "'news sites domains.ipynb'\r\n",
      " old_db.py\r\n",
      " old_utils.py\r\n",
      " plan.md\r\n",
      "'process seen tweets.ipynb'\r\n",
      " __pycache__\r\n",
      "'save profile.ipynb'\r\n",
      " second_batch.csv\r\n",
      " seen.csv\r\n",
      " seen_old.csv\r\n",
      " t\r\n",
      " training.db\r\n",
      "'twitter api 2 context annotations.ipynb'\r\n",
      " twitter.db\r\n",
      " uci-news-aggregator.csv\r\n",
      " Untitled.ipynb\r\n",
      "'upload to collection.ipynb'\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
