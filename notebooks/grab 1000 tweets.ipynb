{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import re\n",
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load tweets older then two weeks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tweets(db_path, days):\n",
    "    time_delta = date.today() - timedelta(days=days)\n",
    "    cnx = sqlite3.connect(db_path)\n",
    "    query = f\"SELECT id,user, full_text, created_at, lang, quoted_status, in_reply_to_status_id FROM tweets WHERE created_at < '{str(time_delta)}'\"\n",
    "    #TODO add restrain, to remove tweets I liked, but for that I need to setup another cron job too.\n",
    "    df = pd.read_sql_query(\n",
    "        query,\n",
    "        cnx,\n",
    "    )\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets = load_tweets(\"../home.db\", days=21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_tweets.columns:\n",
    "    if df_tweets[col].dtype == \"float64\":\n",
    "        df_tweets[col] = df_tweets[col].fillna(0).astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user</th>\n",
       "      <th>full_text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>lang</th>\n",
       "      <th>quoted_status</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>contains_news</th>\n",
       "      <th>all_news</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34519</th>\n",
       "      <td>1345156352956514307</td>\n",
       "      <td>14622002</td>\n",
       "      <td>@niedakh Yes! Out of maybe 5 places we stayed ...</td>\n",
       "      <td>2021-01-01T23:54:00+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>1345155535168024579</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34520</th>\n",
       "      <td>1345156542295904256</td>\n",
       "      <td>2343198944</td>\n",
       "      <td>Oh weird, twitter doesn't bring up the list wh...</td>\n",
       "      <td>2021-01-01T23:54:46+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>1345155313725562889</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34521</th>\n",
       "      <td>1345157369903239168</td>\n",
       "      <td>14379530</td>\n",
       "      <td>\"in a well-run civilization, the first covid v...</td>\n",
       "      <td>2021-01-01T23:58:03+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34522</th>\n",
       "      <td>1345157575256363008</td>\n",
       "      <td>1025982573665648640</td>\n",
       "      <td>You may remember http://whatdayisitagain.org, ...</td>\n",
       "      <td>2021-01-01T23:58:52+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34523</th>\n",
       "      <td>1345157722002444289</td>\n",
       "      <td>1416500532</td>\n",
       "      <td>The internet is magic https://twitter.com/dotS...</td>\n",
       "      <td>2021-01-01T23:59:27+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>1345157575256363008</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        id                 user  \\\n",
       "34519  1345156352956514307             14622002   \n",
       "34520  1345156542295904256           2343198944   \n",
       "34521  1345157369903239168             14379530   \n",
       "34522  1345157575256363008  1025982573665648640   \n",
       "34523  1345157722002444289           1416500532   \n",
       "\n",
       "                                               full_text  \\\n",
       "34519  @niedakh Yes! Out of maybe 5 places we stayed ...   \n",
       "34520  Oh weird, twitter doesn't bring up the list wh...   \n",
       "34521  \"in a well-run civilization, the first covid v...   \n",
       "34522  You may remember http://whatdayisitagain.org, ...   \n",
       "34523  The internet is magic https://twitter.com/dotS...   \n",
       "\n",
       "                      created_at lang        quoted_status  \\\n",
       "34519  2021-01-01T23:54:00+00:00   en                    0   \n",
       "34520  2021-01-01T23:54:46+00:00   en                    0   \n",
       "34521  2021-01-01T23:58:03+00:00   en                    0   \n",
       "34522  2021-01-01T23:58:52+00:00   en                    0   \n",
       "34523  2021-01-01T23:59:27+00:00   en  1345157575256363008   \n",
       "\n",
       "      in_reply_to_status_id  contains_news  all_news  \n",
       "34519   1345155535168024579              0         0  \n",
       "34520   1345155313725562889              0         0  \n",
       "34521                  None              0         0  \n",
       "34522                  None              0         0  \n",
       "34523                  None              0         0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_qt = df_tweets[[\"id\", \"full_text\"]].copy()\n",
    "# df_qt.columns = [\"quoted_status\", \"quoted_text\"]\n",
    "# df_tweets = df_tweets.merge(df_qt, on=\"quoted_status\", how=\"left\")\n",
    "\n",
    "# df_r = df_tweets[[\"id\", \"full_text\"]].copy()\n",
    "# df_r.columns = ['in_reply_to_status_id', 'reply_text']\n",
    "# df_tweets = df_tweets.merge(df_r, on=\"in_reply_to_status_id\", how=\"left\")\n",
    "\n",
    "# df_tweets[\"all_text\"] = (\n",
    "#     df_tweets[\"full_text\"].astype(str)\n",
    "#     + df_tweets[\"quoted_status\"].astype(str)\n",
    "#     + df_tweets[\"in_reply_to_status_id\"].astype(str)\n",
    "# )\n",
    "\n",
    "# df.drop([\"in_reply_to_status_id\"], axis=1, inplace=True)\n",
    "# df.drop([\"quoted_status\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_url(tweet):\n",
    "    return re.findall(r\"http\\S+\", tweet)\n",
    "\n",
    "\n",
    "def clean_links(tweet):\n",
    "    tweet = re.sub(r\"bit.ly/\\S+\", \"\", tweet)\n",
    "    tweet = re.sub(r\"t.co/\\S+\", \"\", tweet)\n",
    "    tweet = re.sub(r\"buff.ly/\\S+\", \"\", tweet)\n",
    "    tweet = re.sub(r\"twitter.com/\\S+\", \"\", tweet)\n",
    "    return tweet\n",
    "\n",
    "\n",
    "def get_domain(url):\n",
    "    domain = urlparse(url).netloc\n",
    "    dot_split = domain.split(\".\")\n",
    "    if len(dot_split) > 2:\n",
    "        return \".\".join(dot_split[1:])\n",
    "    else:\n",
    "        return domain\n",
    "\n",
    "\n",
    "def remove_empty_str(l):\n",
    "    for i in l:\n",
    "        if len(i) == 0:\n",
    "            l.remove(i)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# function for df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def find_news(df, news_domains_list):\n",
    "\n",
    "    df[\"urls\"] = df[\"full_text\"].apply(find_url)\n",
    "    df[\"urls\"] = df.urls.apply(lambda x: [clean_links(d) for d in x])\n",
    "    df[\"domains\"] = df.urls.apply(lambda x: [get_domain(d) for d in x])\n",
    "    df[\"domains\"] = df.domains.apply(remove_empty_str)\n",
    "    df.drop([\"urls\"], axis=1, inplace=True)\n",
    "\n",
    "    new_columns_list = []\n",
    "    max_nr_dom = df.domains.str.len().max()\n",
    "    for i in range(max_nr_dom):\n",
    "        new_columns_list.append(f\"domain{i+1}\")\n",
    "    df[new_columns_list] = pd.DataFrame(df.domains.tolist())\n",
    "\n",
    "    for col in new_columns_list:\n",
    "        df[col] = df[col].isin(news_domains_list)\n",
    "\n",
    "    df.drop([\"domains\"], axis=1, inplace=True)\n",
    "\n",
    "    df[\"contains_news\"] = df[new_columns_list].sum(axis=1)\n",
    "    df[\"contains_news\"] = df.contains_news.apply(lambda x: x if x == 0 else 1)\n",
    "    df.drop(new_columns_list, axis=1, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "def drop_contains(df, column_name, word_list):\n",
    "    for string in word_list:\n",
    "        df[\"lower\"] = df[\"full_text\"].str.lower()\n",
    "        df = df[df[\"lower\"].str.contains(string)]\n",
    "        df.drop([\"lower\"], axis=1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"news_domains.txt\", \"r\") as f:\n",
    "    news_domains = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 426 ms, sys: 7.55 ms, total: 433 ms\n",
      "Wall time: 433 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_tweets = find_news(df_tweets, news_domains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def news_in_qt_rt(df):\n",
    "    df[\"all_news\"] = df[\"contains_news\"].copy()\n",
    "\n",
    "    df_qt = df[[\"id\", \"contains_news\"]].copy()\n",
    "    df_qt.columns = [\"quoted_status\", \"qt_news\"]\n",
    "    df = df.merge(df_qt, on=\"quoted_status\", how=\"left\")\n",
    "    df[\"qt_news\"] = df[\"qt_news\"].fillna(0).astype(np.int64)\n",
    "    df[\"all_news\"] = df[\"qt_news\"].astype(np.int64) + df[\"contains_news\"].astype(np.int64)\n",
    "    # df.drop([\"quoted_status\"], axis=1, inplace=True)\n",
    "\n",
    "    df_qt = df[[\"id\", \"contains_news\"]].copy()\n",
    "    df_qt.columns = [\"in_reply_to_status_id\", \"rt_news\"]\n",
    "    df = df.merge(df_qt, on=\"in_reply_to_status_id\", how=\"left\")\n",
    "    df[\"rt_news\"] = df[\"rt_news\"].fillna(0).astype(np.int64)\n",
    "    df[\"all_news\"] = df[\"rt_news\"].astype(np.int64) + df[\"all_news\"].astype(np.int64)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_tweets.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user</th>\n",
       "      <th>full_text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>lang</th>\n",
       "      <th>quoted_status</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>contains_news</th>\n",
       "      <th>all_news</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2627602600</td>\n",
       "      <td>21454322</td>\n",
       "      <td>Went on a USO trip to Guantanamo Bay, Cuba a f...</td>\n",
       "      <td>2009-07-14T05:15:27+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70261648811761665</td>\n",
       "      <td>5416652</td>\n",
       "      <td>I wish I had kept my 1,700 BTC @ $0.06 instead...</td>\n",
       "      <td>2011-05-16T22:57:37+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>177008089394970624</td>\n",
       "      <td>5110861</td>\n",
       "      <td>In 1996 a man took a NZ radio station hostage,...</td>\n",
       "      <td>2012-03-06T12:29:51+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>234002950274560000</td>\n",
       "      <td>108471631</td>\n",
       "      <td>What is she thinking? https://twitter.com/MELA...</td>\n",
       "      <td>2012-08-10T19:07:06+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>281811460718477312</td>\n",
       "      <td>16298441</td>\n",
       "      <td>did you know that the bible doesn't actually c...</td>\n",
       "      <td>2012-12-20T17:21:02+00:00</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id       user  \\\n",
       "0          2627602600   21454322   \n",
       "1   70261648811761665    5416652   \n",
       "2  177008089394970624    5110861   \n",
       "3  234002950274560000  108471631   \n",
       "4  281811460718477312   16298441   \n",
       "\n",
       "                                           full_text  \\\n",
       "0  Went on a USO trip to Guantanamo Bay, Cuba a f...   \n",
       "1  I wish I had kept my 1,700 BTC @ $0.06 instead...   \n",
       "2  In 1996 a man took a NZ radio station hostage,...   \n",
       "3  What is she thinking? https://twitter.com/MELA...   \n",
       "4  did you know that the bible doesn't actually c...   \n",
       "\n",
       "                  created_at lang  quoted_status in_reply_to_status_id  \\\n",
       "0  2009-07-14T05:15:27+00:00   en              0                  None   \n",
       "1  2011-05-16T22:57:37+00:00   en              0                  None   \n",
       "2  2012-03-06T12:29:51+00:00   en              0                  None   \n",
       "3  2012-08-10T19:07:06+00:00   en              0                  None   \n",
       "4  2012-12-20T17:21:02+00:00   en              0                  None   \n",
       "\n",
       "   contains_news  all_news  \n",
       "0              0         0  \n",
       "1              0         0  \n",
       "2              1         1  \n",
       "3              0         0  \n",
       "4              0         0  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 34524 entries, 0 to 34523\n",
      "Data columns (total 9 columns):\n",
      " #   Column                 Non-Null Count  Dtype \n",
      "---  ------                 --------------  ----- \n",
      " 0   id                     34524 non-null  int64 \n",
      " 1   user                   34524 non-null  int64 \n",
      " 2   full_text              34524 non-null  object\n",
      " 3   created_at             34524 non-null  object\n",
      " 4   lang                   34524 non-null  object\n",
      " 5   quoted_status          34524 non-null  int64 \n",
      " 6   in_reply_to_status_id  8342 non-null   object\n",
      " 7   contains_news          34524 non-null  int64 \n",
      " 8   all_news               34524 non-null  int64 \n",
      "dtypes: int64(5), object(4)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"in_reply_to_status_id\"] = df[\"in_reply_to_status_id\"].fillna(0).astype(np.int64)\n",
    "\n",
    "df_qt = df[[\"id\", \"contains_news\"]].copy()\n",
    "df_qt.columns = [\"in_reply_to_status_id\", \"rt_news\"]\n",
    "df = df.merge(df_qt, on=\"in_reply_to_status_id\", how=\"left\")\n",
    "df[\"rt_news\"] = df[\"rt_news\"].fillna(0).astype(np.int64)\n",
    "df[\"all_news\"] = df[\"rt_news\"].astype(np.int64) + df[\"all_news\"].astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(df_qt, on=\"in_reply_to_status_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You are trying to merge on object and int64 columns. If you wish to proceed you should use pd.concat",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-36-728d71197814>\u001b[0m in \u001b[0;36mnews_in_qt_rt\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mdf_qt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"contains_news\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mdf_qt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"in_reply_to_status_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rt_news\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_qt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"in_reply_to_status_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"left\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"rt_news\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"rt_news\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"all_news\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"rt_news\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"all_news\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mlb/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m   7944\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmerge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7945\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7946\u001b[0;31m         return merge(\n\u001b[0m\u001b[1;32m   7947\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7948\u001b[0m             \u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mlb/lib/python3.8/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m ) -> \"DataFrame\":\n\u001b[0;32m---> 74\u001b[0;31m     op = _MergeOperation(\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mlb/lib/python3.8/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0;31m# validate the merge keys dtypes. We may need to coerce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m         \u001b[0;31m# to avoid incompatible dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 656\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_coerce_merge_keys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m         \u001b[0;31m# If argument passed to validate,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mlb/lib/python3.8/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m_maybe_coerce_merge_keys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1163\u001b[0m                     \u001b[0minferred_right\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstring_types\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0minferred_left\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1164\u001b[0m                 ):\n\u001b[0;32m-> 1165\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m             \u001b[0;31m# datetimelikes must match exactly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: You are trying to merge on object and int64 columns. If you wish to proceed you should use pd.concat"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_tweets = news_in_qt_rt(df_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_tweets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets[df_tweets.id == 1197689942396174336]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# remove seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seen_tweets = pd.read_csv(\"seen.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seen_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seen_tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seen_tweets.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets[df_tweets[\"id\"].isin(seen_tweets[\"tweet_id\"].tolist())].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(df_tweets.shape)\n",
    "df_tweets = df_tweets[~df_tweets[\"id\"].isin(seen_tweets[\"tweet_id\"].tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fiter out non english tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets = df_tweets[df_tweets[\"lang\"] == \"en\"]\n",
    "df_tweets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# suffle them and filter out news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets[df_tweets[\"contains_news\"] == 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_contains(df, column_name, str_list, lower=True):\n",
    "    for string in str_list:\n",
    "        if lower:\n",
    "            df[\"filter\"] = df[column_name].str.lower().copy()\n",
    "        if not lower:\n",
    "            df[\"filter\"] = df[column_name].copy()\n",
    "        df = df_tweets[~df[\"filter\"].str.contains(string)]\n",
    "        df = df.drop([\"filter\"], axis=1).copy()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "🍿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_contains(df, column_name, str_list, lower=True):\n",
    "    for string in str_list:\n",
    "        if lower:\n",
    "            df[\"filter\"] = df[column_name].str.lower().copy()\n",
    "        if not lower:\n",
    "            df[\"filter\"] = df[column_name].copy()\n",
    "        df = df_tweets[df[\"filter\"].str.contains(string)]\n",
    "        df = df.drop([\"filter\"], axis=1).copy()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_to_show = [\"🍿\"]\n",
    "show_contains(df_tweets, column_name=\"full_text\", str_list = str_to_show, lower=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_to_drop = [\"breaking:\"]\n",
    "df_tweets = drop_contains(df_tweets, column_name=\"full_text\", str_list = str_to_drop)\n",
    "df_tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_to_drop = [\"GOP\"]\n",
    "df_tweets = drop_contains(df_tweets, column_name=\"full_text\", str_list = str_to_drop, lower=False)\n",
    "df_tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = \"breaking:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets[\"lower\"] = df_tweets[\"full_text\"].str.lower().copy()\n",
    "df_tweets = df_tweets[~df_tweets[\"lower\"].str.contains(string)]\n",
    "df_tweets.drop([\"lower\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets[\"full_text\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "to_custom_news_feed = (\n",
    "    df_tweets[df_tweets[\"contains_news\"] == 0]\n",
    "    .sample(frac=1)\n",
    "    .reset_index(drop=True)[:1000]\n",
    ")\n",
    "to_custom_news_feed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_custom_news_feed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_custom_news_feed[[\"id\", \"user\"]].to_csv(\"batch_to_add.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "642.15px",
    "left": "1714.93px",
    "right": "20px",
    "top": "120px",
    "width": "409.067px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
